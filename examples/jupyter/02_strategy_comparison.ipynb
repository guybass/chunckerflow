{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChunkFlow: Strategy Comparison\n",
    "\n",
    "This notebook demonstrates how to compare multiple chunking strategies to find the best approach for your use case.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. How to set up multiple strategies for comparison\n",
    "2. How to evaluate strategies with multiple metrics\n",
    "3. How to interpret comparison results\n",
    "4. How to make data-driven decisions about chunking strategies\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install chunk-flow[huggingface,viz]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import numpy as np\n",
    "from chunk_flow.chunking import StrategyRegistry\n",
    "from chunk_flow.embeddings import EmbeddingProviderFactory\n",
    "from chunk_flow.evaluation import EvaluationPipeline, StrategyComparator\n",
    "from chunk_flow.analysis import ResultsDataFrame\n",
    "\n",
    "print(\"âœ“ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sample Document\n",
    "\n",
    "We'll use a longer document about AI to better demonstrate strategy differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"\n",
    "# Artificial Intelligence: A Comprehensive Overview\n",
    "\n",
    "Artificial Intelligence (AI) represents one of the most transformative technologies of the 21st century. \n",
    "It encompasses the development of computer systems capable of performing tasks that typically require \n",
    "human intelligence, such as visual perception, speech recognition, decision-making, and language translation.\n",
    "\n",
    "## Historical Context\n",
    "\n",
    "The concept of AI dates back to ancient mythology, but modern AI research began in the 1950s. Alan Turing's \n",
    "groundbreaking paper \"Computing Machinery and Intelligence\" posed the famous question: \"Can machines think?\" \n",
    "This led to the Turing Test, a criterion for determining machine intelligence.\n",
    "\n",
    "The term \"Artificial Intelligence\" was coined by John McCarthy in 1956 at the Dartmouth Conference, which \n",
    "is considered the birth of AI as a field. Early optimism led to predictions that human-level AI would be \n",
    "achieved within a generation. However, the field experienced several \"AI winters\" - periods of reduced \n",
    "funding and interest due to unmet expectations.\n",
    "\n",
    "## Machine Learning Fundamentals\n",
    "\n",
    "Machine learning, a subset of AI, has become the dominant approach in modern AI systems. Instead of \n",
    "explicitly programming rules, machine learning algorithms learn patterns from data.\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "Supervised learning algorithms learn from labeled training data. The algorithm receives input-output \n",
    "pairs and learns to map inputs to correct outputs. Common applications include:\n",
    "\n",
    "- Image classification (identifying objects in photos)\n",
    "- Spam detection in email\n",
    "- Credit scoring and fraud detection\n",
    "- Medical diagnosis from symptoms\n",
    "\n",
    "Popular supervised learning algorithms include linear regression, logistic regression, decision trees, \n",
    "random forests, support vector machines, and neural networks.\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "Unsupervised learning finds patterns in unlabeled data without predefined categories. The algorithm \n",
    "discovers hidden structures on its own. Key techniques include:\n",
    "\n",
    "- Clustering: Grouping similar data points (customer segmentation, document organization)\n",
    "- Dimensionality reduction: Simplifying data while preserving important information (PCA, t-SNE)\n",
    "- Anomaly detection: Identifying unusual patterns (fraud detection, system monitoring)\n",
    "- Association rule learning: Discovering relationships between variables (market basket analysis)\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "Reinforcement learning trains agents to make sequences of decisions by rewarding desired behaviors and \n",
    "penalizing undesired ones. This approach has achieved remarkable success in:\n",
    "\n",
    "- Game playing (AlphaGo defeating world champions at Go)\n",
    "- Robotics (teaching robots to walk, grasp objects)\n",
    "- Autonomous vehicles (navigation and decision-making)\n",
    "- Resource optimization (data center cooling, traffic light control)\n",
    "\n",
    "## Deep Learning Revolution\n",
    "\n",
    "Deep learning, based on artificial neural networks with multiple layers, has driven recent AI breakthroughs. \n",
    "The \"deep\" in deep learning refers to the number of layers in the network.\n",
    "\n",
    "### Neural Network Architecture\n",
    "\n",
    "Deep neural networks consist of:\n",
    "- Input layer: Receives raw data\n",
    "- Hidden layers: Extract increasingly abstract features\n",
    "- Output layer: Produces predictions or classifications\n",
    "\n",
    "Key innovations enabling deep learning success:\n",
    "- GPU acceleration for parallel computation\n",
    "- Large labeled datasets (ImageNet, Common Crawl)\n",
    "- Improved training algorithms (backpropagation, Adam optimizer)\n",
    "- Regularization techniques (dropout, batch normalization)\n",
    "\n",
    "### Convolutional Neural Networks (CNNs)\n",
    "\n",
    "CNNs revolutionized computer vision by automatically learning spatial hierarchies of features. Applications:\n",
    "- Image classification and object detection\n",
    "- Facial recognition systems\n",
    "- Medical image analysis (detecting tumors, diagnosing diseases)\n",
    "- Autonomous vehicle perception\n",
    "\n",
    "### Recurrent Neural Networks (RNNs)\n",
    "\n",
    "RNNs and their variants (LSTM, GRU) excel at sequential data processing:\n",
    "- Natural language processing and machine translation\n",
    "- Speech recognition and synthesis\n",
    "- Time series prediction (stock prices, weather)\n",
    "- Video analysis and action recognition\n",
    "\n",
    "### Transformer Architecture\n",
    "\n",
    "Transformers, introduced in 2017, use attention mechanisms to process sequential data more effectively. \n",
    "They've become the foundation for modern language models like GPT, BERT, and T5. Benefits include:\n",
    "- Parallel processing (faster training)\n",
    "- Better handling of long-range dependencies\n",
    "- Transfer learning capabilities\n",
    "- Superior performance on NLP tasks\n",
    "\n",
    "## Natural Language Processing\n",
    "\n",
    "NLP enables computers to understand, interpret, and generate human language. Recent advances:\n",
    "\n",
    "- Large language models achieving human-level performance on many tasks\n",
    "- Context-aware translation (Google Translate, DeepL)\n",
    "- Sentiment analysis for social media monitoring\n",
    "- Question answering systems\n",
    "- Text generation and summarization\n",
    "- Conversational AI and chatbots\n",
    "\n",
    "## Computer Vision\n",
    "\n",
    "Computer vision enables machines to interpret visual information:\n",
    "- Object detection and tracking\n",
    "- Semantic segmentation (pixel-level classification)\n",
    "- Pose estimation (understanding human body positions)\n",
    "- 3D reconstruction from 2D images\n",
    "- Visual question answering\n",
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "As AI becomes more powerful, ethical concerns grow:\n",
    "\n",
    "- Bias and fairness: AI systems can perpetuate or amplify existing biases\n",
    "- Privacy: Data collection and surveillance concerns\n",
    "- Transparency: \"Black box\" models are difficult to interpret\n",
    "- Accountability: Who is responsible when AI makes mistakes?\n",
    "- Job displacement: Automation may eliminate certain jobs\n",
    "- Autonomous weapons: Military AI applications raise moral questions\n",
    "\n",
    "## Future Directions\n",
    "\n",
    "The future of AI holds exciting possibilities:\n",
    "\n",
    "- Artificial General Intelligence (AGI): Systems with human-level intelligence across all domains\n",
    "- Explainable AI: Making AI decisions transparent and interpretable\n",
    "- Edge AI: Running AI on devices rather than in the cloud\n",
    "- Quantum machine learning: Leveraging quantum computing for AI\n",
    "- Neuromorphic computing: Brain-inspired hardware architectures\n",
    "- Human-AI collaboration: Augmenting rather than replacing human capabilities\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "AI continues to evolve rapidly, transforming industries and daily life. While challenges remain, \n",
    "responsible development and deployment of AI technologies promise to address some of humanity's \n",
    "most pressing problems while creating new opportunities for innovation and progress.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Document length: {len(document)} characters\")\n",
    "print(f\"Approximate words: {len(document.split())} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Strategies to Compare\n",
    "\n",
    "We'll compare 5 different strategies with various configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create strategies with different configurations\n",
    "strategies = {\n",
    "    \"fixed_small\": StrategyRegistry.create(\n",
    "        \"fixed_size\",\n",
    "        {\"chunk_size\": 300, \"overlap\": 50}\n",
    "    ),\n",
    "    \"fixed_large\": StrategyRegistry.create(\n",
    "        \"fixed_size\",\n",
    "        {\"chunk_size\": 600, \"overlap\": 100}\n",
    "    ),\n",
    "    \"recursive_default\": StrategyRegistry.create(\n",
    "        \"recursive\",\n",
    "        {\"chunk_size\": 500, \"overlap\": 80, \"separators\": [\"\\n\\n\", \"\\n\", \". \", \" \"]}\n",
    "    ),\n",
    "    \"markdown_aware\": StrategyRegistry.create(\n",
    "        \"markdown\",\n",
    "        {\"respect_headers\": True, \"max_chunk_size\": 800}\n",
    "    ),\n",
    "    \"semantic\": StrategyRegistry.create(\n",
    "        \"semantic\",\n",
    "        {\"threshold_percentile\": 75, \"min_chunk_size\": 200}\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(f\"Created {len(strategies)} strategies for comparison:\")\n",
    "for name in strategies.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chunk Document with Each Strategy\n",
    "\n",
    "Let's see how each strategy chunks the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk document with each strategy\n",
    "chunk_results = {}\n",
    "\n",
    "for name, strategy in strategies.items():\n",
    "    result = await strategy.chunk(document, doc_id=\"ai_overview\")\n",
    "    chunk_results[name] = result\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Chunks created: {len(result.chunks)}\")\n",
    "    print(f\"  Processing time: {result.processing_time_ms:.2f}ms\")\n",
    "    print(f\"  Avg chunk size: {np.mean([len(c) for c in result.chunks]):.1f} chars\")\n",
    "    print(f\"  Size range: {min(len(c) for c in result.chunks)} - {max(len(c) for c in result.chunks)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Embeddings for All Chunks\n",
    "\n",
    "We need embeddings to compute semantic metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding provider\n",
    "embedder = EmbeddingProviderFactory.create(\n",
    "    \"huggingface\",\n",
    "    {\n",
    "        \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        \"device\": \"cpu\",\n",
    "        \"normalize\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Generate embeddings for each strategy's chunks\n",
    "embedding_results = {}\n",
    "\n",
    "for name, chunk_result in chunk_results.items():\n",
    "    emb_result = await embedder.embed_texts(chunk_result.chunks)\n",
    "    embedding_results[name] = emb_result\n",
    "    print(f\"{name}: Generated {len(emb_result.embeddings)} embeddings in {emb_result.processing_time_ms:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Each Strategy\n",
    "\n",
    "Now let's evaluate all strategies using multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation pipeline with semantic metrics (no ground truth needed)\n",
    "pipeline = EvaluationPipeline(\n",
    "    metrics=[\n",
    "        \"semantic_coherence\",\n",
    "        \"boundary_quality\",\n",
    "        \"chunk_stickiness\",\n",
    "        \"topic_diversity\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate each strategy\n",
    "evaluation_results = {}\n",
    "\n",
    "for name in strategies.keys():\n",
    "    eval_result = await pipeline.evaluate(\n",
    "        chunks=chunk_results[name].chunks,\n",
    "        embeddings=embedding_results[name].embeddings,\n",
    "    )\n",
    "    evaluation_results[name] = eval_result\n",
    "\n",
    "print(\"âœ“ Evaluation complete for all strategies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Results\n",
    "\n",
    "Let's organize and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for name in strategies.keys():\n",
    "    row = {\n",
    "        \"Strategy\": name,\n",
    "        \"Chunks\": len(chunk_results[name].chunks),\n",
    "        \"Avg Size\": int(np.mean([len(c) for c in chunk_results[name].chunks])),\n",
    "    }\n",
    "    \n",
    "    # Add metric scores\n",
    "    for metric_name, metric_result in evaluation_results[name].items():\n",
    "        row[metric_name] = metric_result.score\n",
    "    \n",
    "    comparison_data.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nStrategy Comparison:\\n\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rank Strategies\n",
    "\n",
    "Let's rank strategies by their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StrategyComparator for advanced analysis\n",
    "report = StrategyComparator.generate_comparison_report(evaluation_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY COMPARISON REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detailed Metric Analysis\n",
    "\n",
    "Let's analyze each metric individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each metric\n",
    "metrics = [\"semantic_coherence\", \"boundary_quality\", \"chunk_stickiness\", \"topic_diversity\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{metric.upper().replace('_', ' ')}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get scores for this metric\n",
    "    scores = [(name, evaluation_results[name][metric].score) for name in strategies.keys()]\n",
    "    \n",
    "    # Sort by score (handle stickiness which is inverse)\n",
    "    if metric == \"chunk_stickiness\":\n",
    "        scores.sort(key=lambda x: x[1])  # Lower is better\n",
    "        print(\"(Lower is better - less topic bleeding across boundaries)\\n\")\n",
    "    else:\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)  # Higher is better\n",
    "        print(\"(Higher is better)\\n\")\n",
    "    \n",
    "    # Print ranked results\n",
    "    for rank, (name, score) in enumerate(scores, 1):\n",
    "        bar = \"â–ˆ\" * int(score * 50)\n",
    "        print(f\"{rank}. {name:20s} {score:.4f} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ResultsDataFrame Analysis\n",
    "\n",
    "Use the ResultsDataFrame for advanced analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResultsDataFrame\n",
    "results_df = ResultsDataFrame.from_evaluation_results(\n",
    "    evaluation_results,\n",
    "    strategy_names=list(strategies.keys())\n",
    ")\n",
    "\n",
    "# Rank strategies by weighted score\n",
    "# Give higher weight to coherence and boundary quality\n",
    "ranked = results_df.rank_strategies(\n",
    "    weights={\n",
    "        \"semantic_coherence\": 2.0,\n",
    "        \"boundary_quality\": 2.0,\n",
    "        \"chunk_stickiness\": 1.0,  # Inverted internally\n",
    "        \"topic_diversity\": 1.0,\n",
    "    },\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(\"\\nWeighted Ranking (Coherence & Boundary Quality weighted 2x):\\n\")\n",
    "print(ranked[[\"strategy\", \"weighted_score\", \"semantic_coherence\", \"boundary_quality\"]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results\n",
    "\n",
    "Save the comparison results for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "output_file = \"strategy_comparison_results.csv\"\n",
    "comparison_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nâœ“ Results exported to {output_file}\")\n",
    "\n",
    "# Also export detailed results\n",
    "results_df.to_csv(\"detailed_results.csv\")\n",
    "print(\"âœ“ Detailed results exported to detailed_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Insights and Recommendations\n",
    "\n",
    "Based on the comparison, here are general insights:\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Semantic Coherence**: Measures how semantically similar content within each chunk is\n",
    "   - Higher scores indicate chunks contain related concepts\n",
    "   - Markdown and semantic strategies typically score higher\n",
    "\n",
    "2. **Boundary Quality**: Measures how well chunks separate distinct topics\n",
    "   - Higher scores indicate cleaner topic boundaries\n",
    "   - Recursive and markdown strategies respect natural boundaries better\n",
    "\n",
    "3. **Chunk Stickiness** (lower is better): Measures topic bleeding across boundaries\n",
    "   - Lower scores indicate less overlap between adjacent chunks\n",
    "   - Fixed-size strategies may have higher stickiness\n",
    "\n",
    "4. **Topic Diversity**: Measures variety of topics across all chunks\n",
    "   - Higher scores indicate chunks cover different topics\n",
    "   - Depends on document structure and strategy\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "- **For structured documents (with headers)**: Use `markdown` or `recursive` strategies\n",
    "- **For maximum speed**: Use `fixed_size` with appropriate chunk size\n",
    "- **For best semantic quality**: Use `semantic` or `recursive` strategies\n",
    "- **For balanced approach**: Use `recursive` (recommended default)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different configurations for each strategy\n",
    "- Test with your specific document types\n",
    "- Consider retrieval metrics if you have query data\n",
    "- Visualize results (see notebook 04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "âœ… How to create and configure multiple chunking strategies\n",
    "âœ… How to chunk documents with different strategies\n",
    "âœ… How to evaluate strategies with semantic metrics\n",
    "âœ… How to compare and rank strategies\n",
    "âœ… How to interpret evaluation results\n",
    "âœ… How to make data-driven decisions about chunking\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Notebook 03**: Deep dive into all 12 evaluation metrics\n",
    "- **Notebook 04**: Visualization and advanced analysis\n",
    "- **Notebook 05**: Using the ChunkFlow REST API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
